gc()
# specify the extension unique to your calibrated files
extension = "inSwissProt"
# get all files of interest
bin_data_files <- list.files(data_dir, pattern = extension, full.names = TRUE, recursive = TRUE)
# and get file path (not reltive!)
input_filenames <- basename(bin_data_files)
# read in all data one by one into an empty list, setting each data frame as a
# new elemnt of the list.
postGMM_data <- list()
print("reading in data")
for (i in 1:length(bin_data_files)) {
print(bin_data_files[[i]])
postGMM_data[[i]] <- read.csv(bin_data_files[[i]], sep =  "\t")
print(i/length(input_filenames)*100)
}
# read in all human proteins for data filtering - from Swiss Prot
Swiis_Prot_data_file <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/data/SwissProtLibrary_2024_01_17.tsv"
Swiss_Prot_Human <- read.csv(file = Swiis_Prot_data_file, sep = "\t")
# clean the names - remove .csv, round the ranges, leave just the range and put mz before it
# reatin information about bin ID == clean names, lower boundary, upper boundary to then put in a dataframe
# Cleaning the names
cleaned_names <- gsub("tyrosine_containing_", "", input_filenames)
cleaned_names <- gsub("_inSwissProt.tsv", "", cleaned_names, fixed = TRUE)
names(postGMM_data) <- cleaned_names
## save tpo objects.e asier to work with:
## bin of interest and decoy bins next to it.
DECOY_minus1 <- postGMM_data[[1]]
DECOY_minus2 <- postGMM_data[[2]]
foreground <- postGMM_data[[6]]
# decoy bins around 0.01 mz
DECOY1 <- postGMM_data[[3]]
DECOY2 <- postGMM_data[[4]]
DECOY3 <- postGMM_data[[5]]
merged_of_interest <- rbind(DECOY_minus1, DECOY_minus2, foreground)
View(merged_of_interest)
# Find unique IDs
unique_DECOY_minus1 <- setdiff(DECOY_minus1$peptidoform_ID, c(DECOY_minus2$peptidoform_ID, foreground$peptidoform_ID))
unique_DECOY_minus2 <- setdiff(DECOY_minus2$peptidoform_ID, c(DECOY_minus1$peptidoform_ID, foreground$peptidoform_ID))
unique_foreground <- setdiff(foreground$peptidoform_ID, c(DECOY_minus1$peptidoform_ID, DECOY_minus2$peptidoform_ID))
unique_DECOY_minus2
unique_DECOY_minus1
# Find unique IDs
unique_DECOY_minus1 <- setdiff(DECOY_minus1$peptidoform_ID,  foreground$peptidoform_ID)
unique_DECOY_minus1
unique_DECOY_minus2 <- setdiff(DECOY_minus2$peptidoform_ID, foreground$peptidoform_ID)
unique_DECOY_minus2
unique_foreground <- setdiff(foreground$peptidoform_ID, c(DECOY_minus1$peptidoform_ID, DECOY_minus2$peptidoform_ID))
unique_foreground
# Find unique IDs
nonunique_DECOY_minus1 <- DECOY_minus1$peptidoform_ID %in%  foreground$peptidoform_ID
nonunique_DECOY_minus1
DECOY_minus1$peptidoform_ID
View(DECOY_minus1)
# Find unique IDs
unique_DECOY_minus1 <- setdoff(DECOY_minus1$peptidoform_id,  foreground$peptidoform_id)
# Find unique IDs
unique_DECOY_minus1 <- setdiff(DECOY_minus1$peptidoform_id,  foreground$peptidoform_id)
unique_DECOY_minus1
unique_DECOY_minus2
unique_DECOY_minus2 <- setdiff(DECOY_minus2$peptidoform_id, foreground$peptidoform_id)
unique_DECOY_minus2
merged_of_interest <- rbind(DECOY_minus1, DECOY_minus2, foreground) %>% unique()
e
unique_foreground <- setdiff(foreground$peptidoform_id, c(DECOY_minus1$peptidoform_id, DECOY_minus2$peptidoform_id))
unique_foreground
write.csv(merged_of_interest, file = "../out/potential_sulfo_peptidoforms.csv", row.names = FALSE)
merged_plus_side <-  rbind(DECOY1, DECOY2, DECOY3) %>% unique()
unique_DECOY2 <- setdiff(DECOY2$peptidoform_id,  DECOY1$peptidoform_id)
unique_DECOY3 <- setdiff(DECOY3$peptidoform_id, DECOY1$peptidoform_id)
unique_DECOY1 <- setdiff(DECOY1$peptidoform_id, c(DECOY2$peptidoform_id, DECOY3$peptidoform_id))
# 166 not in DECOY1 bin
unique_DECOY3 <- setdiff(DECOY3$peptidoform_id, c(DECOY2$peptidoform_id,DECOY1$peptidoform_id))
library(tidyverse)
library(stringr)
project_dir = "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/"
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/data/"
gc()
###### Function to get clean filenames, and round and extract bin boundaries ######
clean_round_extract <- function(name, index) {
#separate the name into pars splitting at _
parts <- unlist(strsplit(name, "_"))
# Rounding the numbers to the fourth decimal place; lower bin boundary is the 2nd part, upper is the 3rd part
lower <- round(as.numeric(parts[2]), 4)
upper <- round(as.numeric(parts[3]), 4)
# Storing the boundaries
# index = 1
lower_boundaries[length(lower_boundaries) + 1] <<- lower
upper_boundaries[length(upper_boundaries) + 1] <<- upper
# Reconstructing the cleaned name (and returning it)
return(paste0("mz_", lower, "_", upper))
}
clean_data <- function(data) {
for (i in 1:ncol(data)) {
cleaned_col <- lapply(data[, i], function(x) {
clean_string <- gsub("\\[|\\]|'", "", x)
if (i == 5) {
clean_string <- gsub(";", ",", clean_string)
}
elements <- unlist(strsplit(clean_string, ',\\s*'))
return(elements)
})
if (i == 2) {
data[, i] <- sapply(cleaned_col, function(x) paste(x, collapse = ", "))
} else {
data[, i] <- sapply(cleaned_col, function(x) paste(unique(x), collapse = ", "))
}
}
return(data)
}
# function to clean the protein IDs in the Input data
ProteinIDCleaningFunction <- function(IDs) {
# step one, deal with NX_ etries
# Remove "NX_" prefix and any the suffix following a dash
cleaned_IDs <- gsub("(^NX_[^-]+)-.*", "\\1", IDs)
# step 2, deal with sp/ID/ cases
# Keep everything after "sp|" and before the second "|"
cleaned_IDs <- gsub(".*sp\\|([^|]+)\\|.*", "\\1", cleaned_IDs)
# step 3 deal with gi|315259111|ref|NP_001186752.1| cases
cleaned_IDs <- gsub(".*gi\\|[^|]+\\|ref\\|(NP_[^|]+).*", "\\1", cleaned_IDs)
# looks for strings starting with gi and keeps
# all text after the first occurance of NP_ up until but excluding the first subsequent |
# # Step 4: Handle cases starting with "CONTRIB" and keep everything after the last underscore "_"
# cleaned_IDs <- gsub("^CONTRIB_([^_]+)_.*", "\\1", cleaned_IDs)
# ### NB: These are gene names and not UniProt Entry IDs, so we actually want to do that step later and convert from gene name to UniProt ID?
# after cleaning,keep only the unique IDs at this stage
cleaned_IDs <- unique(cleaned_IDs)
return(cleaned_IDs)
}
## for getting next prot and Ref seq IDs from the SwissProt library
split_ids <- function(string) {
# First, try splitting with "; "
split_result <- strsplit(string, "; ")
# If the length of any split_result is 1, it means there was no "; " to split on
# In this case, try splitting with just ";"
if (any(sapply(split_result, length) == 1)) {
split_result <- strsplit(string, ";")
}
return(split_result)
}
## to process a sublist of a list of lists where each sublist is a row cell of
# the protein IDs.
# for each sublist of IDs:
#
# 1) check if any of the IDs have a hit in Swiss_Prot_Human$Entry
# if yes replace that sublist with only the IDs with a hit (unlikely to be multiple)
# 2) if not check if any of the IDs have a hit in Swiss_Prot_Human$neXtProt
# if yes retrieve the Swiss_Prot_Human$Entry for that row of Siwss_Prot_Human, then retain that Entry ID and replace the sublist with it
# 3) if not, check if any of the IDs have a hit in Swiss_Prot_Human$RefSeq
# if yes retrieve the Swiss_Prot_Human$Entry for that row of Siwss_Prot_Human, then retain that Entry ID and replace the sublist with it
# if not keep the sublist as it is
process_sublist <- function(sublist, Swiss_Prot_Human, neXtProt_list, RefSeq_list) {
# Check for hits in Swiss_Prot_Human$Entry
entry_hits <- sublist[sublist %in% Swiss_Prot_Human$Entry]
if (length(entry_hits) > 0) {
return(entry_hits)
}
# Check for hits in Swiss_Prot_Human$neXtProt
for (id in sublist) {
if (any(sapply(neXtProt_list, function(x) id %in% x))) {
matching_row <- which(sapply(neXtProt_list, function(x) id %in% x))
return(Swiss_Prot_Human$Entry[matching_row])
}
}
# Check for hits in Swiss_Prot_Human$RefSeq
for (id in sublist) {
if (any(sapply(RefSeq_list, function(x) id %in% x))) {
matching_row <- which(sapply(RefSeq_list, function(x) id %in% x))
return(Swiss_Prot_Human$Entry[matching_row])
}
}
# If no matches, return the original sublist
return(sublist)
}
#### subsetting swiss prot gene ids amnd returning uniprot ones for enrichment
extractEnsemblGeneIDs <- function(dataSet, uniprotMapping) {
# subset to only include IDs present in UniProt mapping
subsetData <- dataSet[dataSet$cleaned_protein_IDs %in% uniprotMapping$uniprotswissprot,]
# match SwissProt IDs in the UniProt data frame to get the position index
matchedIndices <- match(subsetData$cleaned_protein_IDs, uniprotMapping$uniprotswissprot)
# rxtract corresponding ENSEMBL Gene IDs
ensemblGeneIDs <- uniprotMapping$ensembl_gene_id[matchedIndices]
# remove NAs if any (in case some SwissProt IDs didn't have a match)
ensemblGeneIDs <- na.omit(ensemblGeneIDs)
return(ensemblGeneIDs)
}
# TODO: turn beow into a function to keep my environment tidy?
# # List of all objects in the environment
# all_objects <- ls()
#
# # List of objects to keep (replace these with your actual data object names)
# data_objects <- c("postGMM_data")
#
# # Objects to remove
# objects_to_remove <- setdiff(all_objects, data_objects)
#
# # Remove the objects
# rm(list = objects_to_remove)
#
# # Clear objects_to_remove to clean up
# rm(objects_to_remove)
#
# rm("all_objects", "data_objects")
# specify the extension unique to your calibrated files
extension = "postGMM"
# get all files of interest
bin_data_files <- list.files(data_dir, pattern = extension, full.names = TRUE, recursive = TRUE)
# and get file path (not reltive!)
input_filenames <- basename(bin_data_files)
input_filenames
names(postGMM_data)
# this is the bin of interest where we expect to find enrichment of sulfotyr
bin_of_interest <- cleaned_postGMM_data[["mz_-0.0125_-0.0075"]]
# for our foreground we only really want phosphotyrosine-containing peptides in
# the bin of interest; reflect that in the background too!
## NB: PTM assignment might not be 100% correct and we want to actually include
# all tyrosine-containing peptidoforms, not just these assigned to have a
# phosphotyrosine because some phosphogroups assigned to be positionally on a
# Threonine or Serine might actually be on a Tyrosine.
tyrosines_containing_foreground <- bin_of_interest[grepl("Y", bin_of_interest$peptidoform_id), ]
# first generate a list of lists with the foreground IDs
# the list is the protein IDs column, with each sublist representinc a row cell split at the ',' separator between different IDs
foreground_id_list <- lapply(strsplit(tyrosines_containing_foreground$protein, ", "), function(x) unlist(strsplit(x, ", ")))
# clean them up to be able to match bakc to SwissProt library
clean_foreground_ID_list  <- lapply(foreground_id_list, ProteinIDCleaningFunction)
clean_foreground_ID_list
# keep only unique IDs for each row (sublist)
foreground_cleaned_IDs <- lapply(clean_foreground_ID_list, unique)
foreground_cleaned_IDs
# process each sublist in foreground_cleaned_IDs to return the SwissProt Entry
# if there is one, if not retain prevous ID(s)
foreground_cleaned_IDs <- lapply(foreground_cleaned_IDs, process_sublist, Swiss_Prot_Human, neXtProt_list, RefSeq_list)
foreground_cleaned_IDs
# Flatten the foreground_cleaned_IDs list to then add to our data frame
flattened_foreground_cleaned_IDs <- sapply(foreground_cleaned_IDs, function(x) paste(x, collapse = ","))
flattened_foreground_cleaned_IDs
tyrosines_containing_foreground$cleaned_protein_IDs <- flattened_foreground_cleaned_IDs
# filter to only include rows with SwissProt Entry hits
tyrosines_containing_foreground_inSwissProt <- tyrosines_containing_foreground[tyrosines_containing_foreground$cleaned_protein_IDs %in% Swiss_Prot_Human$Entry,]
tyrosines_containing_foreground_inSwissProt
View(tyrosines_containing_foreground_inSwissProt)
# also write the ones with no hit
tyrosines_containing_foreground_UNMATCHED <- tyrosines_containing_foreground[!tyrosines_containing_foreground$cleaned_protein_IDs %in% Swiss_Prot_Human$Entry,]
View(tyrosines_containing_background)
View(tyrosines_containing_foreground_inSwissProt)
foreground_proteins <- tyrosines_containing_foreground_inSwissProt$cleaned_protein_IDs
foreground_protein_counts <- table(foreground_proteins)
foreground_protein_counts
protein_counts_df <- as.data.frame(foreground_protein_counts, stringsAsFactors=FALSE)
names(protein_counts_df) <- c("ProteinID", "Count")
# sort in descending order by freq
protein_counts_df <- protein_counts_df[order(-protein_counts_df$Count), ]
protein_counts_df
View(protein_counts_df)
# assign a rank
protein_counts_df$Rank <- seq_len(nrow(protein_counts_df))
View(protein_counts_df)
#convert to DF
protein_counts_df <- as.data.frame(foreground_protein_counts, stringsAsFactors=FALSE)
names(protein_counts_df) <- c("ProteinID", "Count")
# sort in descending order by freq
protein_counts_df <- protein_counts_df[order(-protein_counts_df$Count), ]
read.csv("./data/ReprogrammingData.csv", header = TRUE, row.names=1)
read.csv("../../../../Desktop/Pathways_Networks_Biomarkers_course-20240117T155156Z-001/Pathways_Networks_Biomarkers_course/Day1/data/ReprogrammingData.csv", header = TRUE, row.names=1)
test<-  read.csv("../../../../Desktop/Pathways_Networks_Biomarkers_course-20240117T155156Z-001/Pathways_Networks_Biomarkers_course/Day1/data/ReprogrammingData.csv", header = TRUE, row.names=1)
DE_results <-  read.csv("../../../../Desktop/Pathways_Networks_Biomarkers_course-20240117T155156Z-001/Pathways_Networks_Biomarkers_course/Day1/data/ReprogrammingData.csv", header = TRUE, row.names=1)
significant_genes <- DE_results[DE_results$adjusted_p_value <= 0.01, "Entrez_ID"]
# Sort by descending value of logFC, then extract the logFC values and annotate with with entrez ID
ranked_gene_list <- DE_results %>% arrange(desc(logFC)) %>% pull(logFC, Entrez_ID)
ranked_gene_list
test <- protein_counts_df %>% arrange(desc(Count)) %>% pull(Count, ProteinID)
test
library(dplyr)
ranked_proteins_list <- protein_counts_df %>% arrange(desc(Count)) %>% pull(Count, ProteinID)
getwd()
read.csv("../data/known_sY_SP_2024_02_20.tsv", header = TRUE)
sY_known <- read.csv("../data/known_sY_SP_2024_02_20.tsv", header = TRUE)
sY_known <- read.csv("../data/known_sY_SP_2024_02_20.tsv", header = TRUE, sep = "\t")
View(sY_known)
sY_potential <- read.csv("../data/potential_sY_SP_2024_02_20.tsv", header = TRUE, sep = "\t")
sY_potential$Transmembrane[1:20]
names(sY_potential)
View(Swiss_Prot_Human)
sY_potential$Transmembrane[sY_potential$Transmembrane == ""]
# Sample gene sets - replace with your actual data
gene_sets <- list(
confirmed_sY = sY_known$Entry,
potential_sY_Golgi = c("geneA", "geneB", "geneC"),
potential_sY_transmembrane = sY_potential$Transmembrane[sY_potential$Transmembrane != ""],
potential_sY_secreted = ,
unlikely_sY_SwissProt =
)
View(sY_potential)
sY_potential$Subcellular.location..CC.[1:15]
has_signal_peptide <- sY_potential[sY_potential$Signal.peptide != "",]
View(has_signal_peptide)
has_signal_peptide2 <- Swiss_Prot_Human[Swiss_Prot_Human$Signal.peptide != "",]
setdiff(has_signal_peptide2, has_signal_peptide)
setdiff(has_signal_peptide2$Entry, has_signal_peptide$Entry)
setdiff(has_signal_peptide2$Protein.names, has_signal_peptide$Protein.names)
setdiff(has_signal_peptide2$Subcellular.location..CC., has_signal_peptide$Subcellular.location..CC.)
library(tidyverse)
library(stringr)
library(dplyr)
###### Function to get clean filenames, and round and extract bin boundaries ######
clean_round_extract <- function(name, index) {
#separate the name into pars splitting at _
parts <- unlist(strsplit(name, "_"))
# Rounding the numbers to the fourth decimal place; lower bin boundary is the 2nd part, upper is the 3rd part
lower <- round(as.numeric(parts[2]), 4)
upper <- round(as.numeric(parts[3]), 4)
# Storing the boundaries
# index = 1
lower_boundaries[length(lower_boundaries) + 1] <<- lower
upper_boundaries[length(upper_boundaries) + 1] <<- upper
# Reconstructing the cleaned name (and returning it)
return(paste0("mz_", lower, "_", upper))
}
clean_data <- function(data) {
for (i in 1:ncol(data)) {
cleaned_col <- lapply(data[, i], function(x) {
clean_string <- gsub("\\[|\\]|'", "", x)
if (i == 5) {
clean_string <- gsub(";", ",", clean_string)
}
elements <- unlist(strsplit(clean_string, ',\\s*'))
return(elements)
})
if (i == 2) {
data[, i] <- sapply(cleaned_col, function(x) paste(x, collapse = ", "))
} else {
data[, i] <- sapply(cleaned_col, function(x) paste(unique(x), collapse = ", "))
}
}
return(data)
}
# function to clean the protein IDs in the Input data
ProteinIDCleaningFunction <- function(IDs) {
# step one, deal with NX_ etries
# Remove "NX_" prefix and any the suffix following a dash
cleaned_IDs <- gsub("(^NX_[^-]+)-.*", "\\1", IDs)
# step 2, deal with sp/ID/ cases
# Keep everything after "sp|" and before the second "|"
cleaned_IDs <- gsub(".*sp\\|([^|]+)\\|.*", "\\1", cleaned_IDs)
# step 3 deal with gi|315259111|ref|NP_001186752.1| cases
cleaned_IDs <- gsub(".*gi\\|[^|]+\\|ref\\|(NP_[^|]+).*", "\\1", cleaned_IDs)
# looks for strings starting with gi and keeps
# all text after the first occurance of NP_ up until but excluding the first subsequent |
# # Step 4: Handle cases starting with "CONTRIB" and keep everything after the last underscore "_"
# cleaned_IDs <- gsub("^CONTRIB_([^_]+)_.*", "\\1", cleaned_IDs)
# ### NB: These are gene names and not UniProt Entry IDs, so we actually want to do that step later and convert from gene name to UniProt ID?
# after cleaning,keep only the unique IDs at this stage
cleaned_IDs <- unique(cleaned_IDs)
return(cleaned_IDs)
}
## for getting next prot and Ref seq IDs from the SwissProt library
split_ids <- function(string) {
# First, try splitting with "; "
split_result <- strsplit(string, "; ")
# If the length of any split_result is 1, it means there was no "; " to split on
# In this case, try splitting with just ";"
if (any(sapply(split_result, length) == 1)) {
split_result <- strsplit(string, ";")
}
return(split_result)
}
## to process a sublist of a list of lists where each sublist is a row cell of
# the protein IDs.
# for each sublist of IDs:
#
# 1) check if any of the IDs have a hit in Swiss_Prot_Human$Entry
# if yes replace that sublist with only the IDs with a hit (unlikely to be multiple)
# 2) if not check if any of the IDs have a hit in Swiss_Prot_Human$neXtProt
# if yes retrieve the Swiss_Prot_Human$Entry for that row of Siwss_Prot_Human, then retain that Entry ID and replace the sublist with it
# 3) if not, check if any of the IDs have a hit in Swiss_Prot_Human$RefSeq
# if yes retrieve the Swiss_Prot_Human$Entry for that row of Siwss_Prot_Human, then retain that Entry ID and replace the sublist with it
# if not keep the sublist as it is
process_sublist <- function(sublist, Swiss_Prot_Human, neXtProt_list, RefSeq_list) {
# Check for hits in Swiss_Prot_Human$Entry
entry_hits <- sublist[sublist %in% Swiss_Prot_Human$Entry]
if (length(entry_hits) > 0) {
return(entry_hits)
}
# Check for hits in Swiss_Prot_Human$neXtProt
for (id in sublist) {
if (any(sapply(neXtProt_list, function(x) id %in% x))) {
matching_row <- which(sapply(neXtProt_list, function(x) id %in% x))
return(Swiss_Prot_Human$Entry[matching_row])
}
}
# Check for hits in Swiss_Prot_Human$RefSeq
for (id in sublist) {
if (any(sapply(RefSeq_list, function(x) id %in% x))) {
matching_row <- which(sapply(RefSeq_list, function(x) id %in% x))
return(Swiss_Prot_Human$Entry[matching_row])
}
}
# If no matches, return the original sublist
return(sublist)
}
#### subsetting swiss prot gene ids amnd returning uniprot ones for enrichment
extractEnsemblGeneIDs <- function(dataSet, uniprotMapping) {
# subset to only include IDs present in UniProt mapping
subsetData <- dataSet[dataSet$cleaned_protein_IDs %in% uniprotMapping$uniprotswissprot,]
# match SwissProt IDs in the UniProt data frame to get the position index
matchedIndices <- match(subsetData$cleaned_protein_IDs, uniprotMapping$uniprotswissprot)
# rxtract corresponding ENSEMBL Gene IDs
ensemblGeneIDs <- uniprotMapping$ensembl_gene_id[matchedIndices]
# remove NAs if any (in case some SwissProt IDs didn't have a match)
ensemblGeneIDs <- na.omit(ensemblGeneIDs)
return(ensemblGeneIDs)
}
# TODO: turn beow into a function to keep my environment tidy?
# # List of all objects in the environment
# all_objects <- ls()
#
# # List of objects to keep (replace these with your actual data object names)
# data_objects <- c("postGMM_data")
#
# # Objects to remove
# objects_to_remove <- setdiff(all_objects, data_objects)
#
# # Remove the objects
# rm(list = objects_to_remove)
#
# # Clear objects_to_remove to clean up
# rm(objects_to_remove)
#
# rm("all_objects", "data_objects")
View(bin_of_interest)
foreground_cleaned_IDs
library(clusterProfiler)
library(org.Hs.eg.db)
library(org.Hs.eg.db)
library(biomaRt)
library(devtools)
foreground_protein_counts
class(foreground_protein_counts)
ranked_proteins_list
project_dir = "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/"
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/in/"
gc()
library(tidyverse)
library(stringr)
library(dplyr)
library(clusterProfiler)
library(org.Hs.eg.db)
library(biomaRt)
library(devtools)
project_dir = "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/"
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/in/"
gc()
project_dir = "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/"
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/in/"
gc()
bin_of_interest <- read.csv(file = paste0(data_dir, "tyrosine_containing_foreground_inSwissProt.tsv"),
header = TRUE,
sep = "\t"
)
project_dir = "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/"
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/07_Enrichment_analysis_custom_background_Sets/in/"
gc()
bin_of_interest <- read.csv(file = paste0(data_dir, "tyrosine_containing_foreground_inSwissProt.tsv"),
header = TRUE,
sep = "\t"
)
View(bin_of_interest)
all_bins_background <- read.csv(file = paste0(data_dir, "tyrosine_containing_background_inSwissProt.tsv"),
header = TRUE,
sep = "\t"
)
SwissProtHuman <- read.csv(file = paste0(data_dir, "SwissProtLibrary_2024_01_17.tsv"),
header = TRUE,
sep = "\t"
)
known_sY <- read.csv(file = paste0(data_dir, "known_sY_SP_2024_02_20.tsv"),
header = TRUE,
sep = "\t"
)
potential_sY <- read.csv(file = paste0(data_dir, "potential_sY_SP_2024_02_20.tsv"),
header = TRUE,
sep = "\t"
)
## for getting next prot and Ref seq IDs from the SwissProt library
split_ids <- function(string) {
# First, try splitting with "; "
split_result <- strsplit(string, "; ")
# If the length of any split_result is 1, it means there was no "; " to split on
# In this case, try splitting with just ";"
if (any(sapply(split_result, length) == 1)) {
split_result <- strsplit(string, ";")
}
return(split_result)
}
# run cleaning to retain SwissProt entry only
# Split Swiss_Prot_Human$neXtProt and Swiss_Prot_Human$RefSeq into lists of IDs
# Apply the split_ids function I wrote; we will need these
neXtProt_list <- lapply(Swiss_Prot_Human$neXtProt, split_ids)
# run cleaning to retain SwissProt entry only
# Split Swiss_Prot_Human$neXtProt and Swiss_Prot_Human$RefSeq into lists of IDs
# Apply the split_ids function I wrote; we will need these
neXtProt_list <- lapply(SwissProtHuman$neXtProt, split_ids)
RefSeq_list <- lapply(SwissProtHuman$RefSeq, split_ids)
library(biomaRt)
## convert the SwissProt IDs to Ensembl gene IDs
# Connect to the Ensembl database
# ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
ensembl <- useEnsembl(biomart = "ensembl", dataset = "hsapiens_gene_ensembl")
library(BiocFileCache)
library(dbplyr)
# need to downgrade devtools for biomart to work #stackoverflow
devtools::install_version("dbplyr", version = "2.3.4")
