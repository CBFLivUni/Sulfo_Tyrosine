negativeProbefData <- subset(fData(target_demoData), CodeClass == "Negative")
neg_probes <- unique(negativeProbefData$TargetName)
target_demoData <-
target_demoData[fData(target_demoData)$DetectionRate >= 0.1 |
fData(target_demoData)$TargetName %in% neg_probes, ]
dim(target_demoData)
#> Features  Samples
#>    10131      221
# retain only detected genes of interest
goi <- goi[goi %in% rownames(target_demoData)]
goi
library(reshape2)  # for melt
library(cowplot)   # for plot_grid
# Graph Q3 value vs negGeoMean of Negatives
ann_of_interest <- "region"
Stat_data <-
data.frame(row.names = colnames(exprs(target_demoData)),
Segment = colnames(exprs(target_demoData)),
Annotation = pData(target_demoData)[, ann_of_interest],
Q3 = unlist(apply(exprs(target_demoData), 2,
quantile, 0.75, na.rm = TRUE)),
NegProbe = exprs(target_demoData)[neg_probes, ])
Stat_data_m <- melt(Stat_data, measure.vars = c("Q3", "NegProbe"),
variable.name = "Statistic", value.name = "Value")
plt1 <- ggplot(Stat_data_m,
aes(x = Value, fill = Statistic)) +
geom_histogram(bins = 40) + theme_bw() +
scale_x_continuous(trans = "log2") +
facet_wrap(~Annotation, nrow = 1) +
scale_fill_brewer(palette = 3, type = "qual") +
labs(x = "Counts", y = "Segments, #")
plt2 <- ggplot(Stat_data,
aes(x = NegProbe, y = Q3, color = Annotation)) +
geom_abline(intercept = 0, slope = 1, lty = "dashed", color = "darkgray") +
geom_point() + guides(color = "none") + theme_bw() +
scale_x_continuous(trans = "log2") +
scale_y_continuous(trans = "log2") +
theme(aspect.ratio = 1) +
labs(x = "Negative Probe GeoMean, Counts", y = "Q3 Value, Counts")
plt3 <- ggplot(Stat_data,
aes(x = NegProbe, y = Q3 / NegProbe, color = Annotation)) +
geom_hline(yintercept = 1, lty = "dashed", color = "darkgray") +
geom_point() + theme_bw() +
scale_x_continuous(trans = "log2") +
scale_y_continuous(trans = "log2") +
theme(aspect.ratio = 1) +
labs(x = "Negative Probe GeoMean, Counts", y = "Q3/NegProbe Value, Counts")
btm_row <- plot_grid(plt2, plt3, nrow = 1, labels = c("B", ""),
rel_widths = c(0.43,0.57))
plot_grid(plt1, btm_row, ncol = 1, labels = c("A", ""))
# Q3 norm (75th percentile) for WTA/CTA  with or without custom spike-ins
target_demoData <- normalize(target_demoData ,
norm_method = "quant",
desiredQuantile = .75,
toElt = "q_norm")
# Background normalization for WTA/CTA without custom spike-in
target_demoData <- normalize(target_demoData ,
norm_method = "neg",
fromElt = "exprs",
toElt = "neg_norm")
# visualize the first 10 segments with each normalization method
boxplot(exprs(target_demoData)[,1:10],
col = "#9EDAE5", main = "Raw Counts",
log = "y", names = 1:10, xlab = "Segment",
ylab = "Counts, Raw")
boxplot(assayDataElement(target_demoData[,1:10], elt = "q_norm"),
col = "#2CA02C", main = "Q3 Norm Counts",
log = "y", names = 1:10, xlab = "Segment",
ylab = "Counts, Q3 Normalized")
boxplot(assayDataElement(target_demoData[,1:10], elt = "neg_norm"),
col = "#FF7F0E", main = "Neg Norm Counts",
log = "y", names = 1:10, xlab = "Segment",
ylab = "Counts, Neg. Normalized")
library(umap)
library(Rtsne)
# update defaults for umap to contain a stable random_state (seed)
custom_umap <- umap::umap.defaults
custom_umap$random_state <- 42
# run UMAP
umap_out <-
umap(t(log2(assayDataElement(target_demoData , elt = "q_norm"))),
config = custom_umap)
pData(target_demoData)[, c("UMAP1", "UMAP2")] <- umap_out$layout[, c(1,2)]
ggplot(pData(target_demoData),
aes(x = UMAP1, y = UMAP2, color = region, shape = class)) +
geom_point(size = 3) +
theme_bw()
library(tidyverse)
install.packages("muma")
install.packages("palmerpenguins")
#| label: load-packages
#| include: false
library(tidyverse)
library(palmerpenguins)
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
install.packages("quarto")
gc()
getwd()
# specify the extension unique to your calibrated files
extension = "postGMM"
batch = ""
# get all calibrated files
calibrated_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
getwd()
wd <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/"
batch = ""
# get all calibrated files
calibrated_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
# get all calibrated files
bin_data_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
# specify the extension unique to your calibrated files
extension = "postGMM"
wd <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/"
batch = ""
# get all calibrated files
bin_data_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
wd <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/data/"
batch = ""
# get all calibrated files
bin_data_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
# extract the folder paths for hist plot f-n
folders <- dirname(calibrated_files)
# extract the folder paths for hist plot f-n
folders <- dirname(bin_data_files)
# and the filenames for input in plot histograms f-n by Andy
input_filenames <- basename(bin_data_files)
# specify the extension unique to your calibrated files
extension = "postGMM"
wd <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/data/"
batch = "" # if any
# get all files of interest
bin_data_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
# extract the folder paths
folders <- dirname(bin_data_files)
# and the filenames
input_filenames <- basename(bin_data_files)
# read in all data one by one into an empty list, setting each data frame as a
# new elemnt of the list.
postGMM_data <- list()
print("reading in data")
for (i in 1:length(bin_data_files)) {
print(bin_data_files[[i]])
postGMM_data[[i]] <- read.csv(bin_data_files[[i]])
print(i/length(input_filenames)*100)
}
# specify the extension unique to your calibrated files
extension = "postGMM"
wd <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/03_Post_GMM_analysis/data/"
batch = "" # if any
# get all files of interest
bin_data_files <- list.files(paste0(wd, batch), pattern = extension, full.names = TRUE, recursive = TRUE)
# extract the folder paths
folders <- dirname(bin_data_files)
# and the filenames
input_filenames <- basename(bin_data_files)
# read in all data one by one into an empty list, setting each data frame as a
# new elemnt of the list.
postGMM_data <- list()
print("reading in data")
for (i in 1:length(bin_data_files)) {
print(bin_data_files[[i]])
postGMM_data[[i]] <- read.csv(bin_data_files[[i]])
print(i/length(input_filenames)*100)
}
names(postGMM_data)
library(tidyverse)
library(stringr)
bin_proportions_df <- as.data.frame(matrix(nrow = 0, ncol = 0))
bin_proportions_df <- as.data.frame(matrix(nrow = 30, ncol = 0))
bin_proportions_df <- as.data.frame(matrix(nrow = length(postGMM_data), ncol = 0))
bin_proportions_df$bin_widths <- input_filenames
View(bin_proportions_df)
# create a data frame to store our results
bin_proportions_df <- as.data.frame(matrix(nrow = length(postGMM_data), ncol = 0))
# create a data frame to store our results
bin_proportions_df <- as.data.frame(matrix(nrow = length(postGMM_data), ncol = 0))
rm(bin_proportions_df)
# create a data frame to store our results
bin_proportions_df <- as.data.frame(matrix(nrow = length(postGMM_data), ncol = 0))
bin_proportions_df$bin_ID <- input_filenames
View(postGMM_data)
names(postGMM_data) <- input_filenames
View(postGMM_data)
library(clusterProfiler)
library(org.Hs.eg.db)
library(biomaRt)
library(devtools)
## convert the SwissProt IDs to Ensembl gene IDs
# Connect to the Ensembl database
ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
# Get the corresponding Entrez IDs
Uniprot = getBM(
attributes=c('ensembl_gene_id','uniprotswissprot'),
mart = ensembl)
View(Uniprot)
getwd()
setwd("C:/Users/jtzve/Desktop/Sufo_Tyrosine/09_USI_generation/scripts")
getwd()
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/06_histograms_of_peptidoforms_of_interest_per_dataset/out/csv_tables_by_peptidoform/"
library(tidyverse)
test<- read.csv("../../06_histograms_of_peptidoforms_of_interest_per_dataset/out/csv_tables_by_peptidoform/merged_data_EHTIKPYSEK_T181_1.csv")
View(test)
head(test)
head(test)[1,]
manual_example <- test[test$spectrum=="Abemaciclib_01201_A08_P012166_B00_A00_R1.08216.08216.2",]
View(test)
manual_example <- test[test$spectrum=="
Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2",]
View(manual_example)
manual_example <- test[test$spectrum == "Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2",]
manual_example
sub("([^-]*)(-.*)?", "\\1", test$dataset_ID
)
View(test)
current_dataset <- sub("([^-]*)(-.*)?", "\\1", manual_example$dataset_ID)
View(manual_example)
scan_number <- manual_example$native_id
scan_number
scan_number_string <- manual_example$native_id
# Use regmatches and regexpr to extract the scan number
scan_number <- as.numeric(regmatches(scan_number_string, regexpr("(?<=scan=)\\d+", scan_number_string, perl = TRUE)))
paste("mzspec", current_dataset, current_data_source, "scan", scan_number, sep = ":")
manual_example <- test[test$spectrum == "Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2",]
current_dataset <- sub("([^-]*)(-.*)?", "\\1", manual_example$dataset_ID)
current_data_source <- manual_example$spectrum # this may be incorrect
scan_number_string <- manual_example$native_id
# Use regmatches and regexpr to extract the scan number
scan_number <- as.numeric(regmatches(scan_number_string, regexpr("(?<=scan=)\\d+", scan_number_string, perl = TRUE)))
paste("mzspec", current_dataset, current_data_source, "scan", scan_number, sep = ":")
# manually constructed example by me:
# read in a test dataset
test<- read.csv("../../06_histograms_of_peptidoforms_of_interest_per_dataset/out/csv_tables_by_peptidoform/merged_data_APVNWYQEK_N115_1_Y243_1.csv")
View(manual_example)
View(test)
# manually constructed example by me:
# read in a test dataset
test<- read.csv("../../06_histograms_of_peptidoforms_of_interest_per_dataset/out/csv_tables_by_peptidoform/merged_data_nIYEFPETDDEEENK_n145_1_T181_1.csv")
View(test)
manual_example <- test[7,]
View(manual_example)
# pick a spectrum == Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2
hist(test$calibrated_error)
# pick a spectrum == Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2
hist(test$calibrated_error, breaks = 30)
# pick a spectrum == Abemaciclib_01201_C07_P012160_B00_A00_R1.02646.02646.2
hist(test$calibrated_error, breaks = 50)
library(tidyverse)
setwd("C:/Users/jtzve/Desktop/Sufo_Tyrosine/10_confident_subset_BOI/scripts/")
data_dir <- "C:/Users/jtzve/Desktop/Sufo_Tyrosine/06_histograms_of_peptidoforms_of_interest_per_dataset/out/csv_tables_by_peptidoform/"
# peptidoforms of interest metadata - subset of proteins  that could be sulfated based on CC
peptidoform_data <- read.csv("../in/potential_sY_peptidoforms_BOI.csv")
View(peptidoform_data)
extension = ".csv"
files_by_peptidoform <- list.files(data_dir, pattern = extension, full.names = FALSE, recursive = TRUE)
files_by_peptidoform[1]
View(peptidoform_data)
# retain peptidofrom id from the filenames
id_in_file_names <- gsub("^merged_data_|\\.csv$", "", files_by_peptidoform)
id_in_file_names
# retain peptidofrom id from the filenames
ids_in_file_names <- gsub("^merged_data_|\\.csv$", "", files_by_peptidoform)
#keep only relevant files
filtered_files <- files_by_peptidoform[ids_in_file_names %in% peptidoform_data$peptidoform_id]
filtered_files
View(peptidoform_data)
View(test)
library(ggplot2)
source("plot_colour_coded_histogram_fun.R")
source("plot_colour_coded_histogram_fun.R")
# and the filenames for input in plot histograms f-n by Andy
input_filenames <- basename(filtered_files)
input_filenames
# extract the folder paths for hist plot f-n
folders <- dirname(filtered_files)
folders
files_by_peptidoform
files_by_peptidoform <- list.files(data_dir, pattern = extension, full.names = TRUE, recursive = TRUE)
# retain peptidofrom id from the filenames
ids_in_file_names <- gsub("^merged_data_|\\.csv$", "", files_by_peptidoform)
ids_in_file_names
# retain peptidofrom id from the filenames
ids_in_file_names <- gsub("*^merged_data_|\\.csv$", "", files_by_peptidoform)
ids_in_file_names
filtered_files
input_filenames <- paste0(data_dir, filtered_files)
input_filenames <- paste0(data_dir, filtered_files)
input_filenames
source("plot_colour_coded_histogram_fun.R")
plot_colour_coded_histogram(absolute_file_path = input_filenames[1],
peptidoform_metadata = peptidoform_data,
mz_binwidth = 0.02)
absolute_file_path = input_filenames[1]
peptidoform_metadata = peptidoform_data
mz_binwidth = 0.02
# first, we read in the .csv file for a peptidoform
temp_data <- read.csv(absolute_file_path)
View(temp_data)
# precalculate min and max calibrated error
min_error <- floor(min(temp_data$calibrated_error) * 10) / 10
max_error <- ceiling(max(temp_data$calibrated_error) * 10) / 10
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
View(temp_data)
mz_binwidth = 0.002
# precalculate min and max calibrated error
min_error <- floor(min(temp_data$calibrated_error) * 10) / 10
max_error <- ceiling(max(temp_data$calibrated_error) * 10) / 10
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
View(temp_data)
# aggregate data for plotting
plot_data <- aggregate(cbind(count = calibrated_error) ~ bin + dataset_ID, data = temp_data, FUN = length)
View(plot_data)
# Create a stacked bar chart
p <- ggplot(plot_data, aes(x = bin, y = count, fill = dataset_ID)) +
geom_bar(stat = "identity", position = "stack") +
scale_x_continuous(breaks = seq(min(plot_data$bin), max(plot_data$bin), by = 1), limits = c(min(bins), max(bins))) +
labs(x = "m/z Bin", y = "Count", title = paste("Histogram of Calibrated Errors for", gsub("^.*/|\\.csv$", "", absolute_file_path))) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
print(p)
min(temp_data$calibrated_error)
min(temp_data$calibrated_error) * 10
floor(min(temp_data$calibrated_error) * 10)
floor(min(temp_data$calibrated_error))
# precalculate min and max calibrated error
min_error <- floor(min(temp_data$calibrated_error)*100) / 10
floor(min(temp_data$calibrated_error)*100)
# precalculate min and max calibrated error
min_error <- floor(min(temp_data$calibrated_error)*100) / 10
min_error
ceiling(max(temp_data$calibrated_error) * 100)
max(temp_data$calibrated_error
)
max_error
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
# aggregate data for plotting
plot_data <- aggregate(cbind(count = calibrated_error) ~ bin + dataset_ID, data = temp_data, FUN = length)
# Create a stacked bar chart
p <- ggplot(plot_data, aes(x = bin, y = count, fill = dataset_ID)) +
geom_bar(stat = "identity", position = "stack") +
scale_x_continuous(breaks = seq(min(plot_data$bin), max(plot_data$bin), by = 1), limits = c(min(bins), max(bins))) +
labs(x = "m/z Bin", y = "Count", title = paste("Histogram of Calibrated Errors for", gsub("^.*/|\\.csv$", "", absolute_file_path))) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
print(p)
head(plot_data)
# precalculate min and max calibrated error
min_error <- min(temp_data$calibrated_error) - mz_binwidth
max_error <- max(temp_data$calibrated_error) + mz_binwidth
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
bins
# precalculate min and max calibrated error
min_error <- floor(min(temp_data$calibrated_error) - mz_binwidth, digits = 3)
bins
# precalculate min and max calibrated error
min_error <- round(min(temp_data$calibrated_error) - mz_binwidth, digits = 3)
# precalculate min and max calibrated error
min_error <- round(min(temp_data$calibrated_error) - mz_binwidth, digits = 2)
# precalculate min and max calibrated error
min_error <- round(min(temp_data$calibrated_error) - 2*mz_binwidth, digits = 2)
max_error <- round(max(temp_data$calibrated_error) + 2*mz_binwidth)
max_error <- round(max(temp_data$calibrated_error) + 2*mz_binwidth, digits = 2)
max(temp_data$calibrated_error
)
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
bins
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
View(temp_data)
# aggregate data for plotting
plot_data <- aggregate(cbind(count = calibrated_error) ~ bin + dataset_ID, data = temp_data, FUN = length)
head(plot_data)
bins
plot_data$binrange <- bins[plot_data$bin]
View(plot_data)
plot_data$binend <- bins[plot_data$bin+1]
View(plot_data)
absolute_file_path = input_filenames[31]
input_filenames
View(peptidoform_data)
absolute_file_path = input_filenames[37]
# first, we read in the .csv file for a peptidoform
temp_data <- read.csv(absolute_file_path)
# precalculate min and max calibrated error
min_error <- round(min(temp_data$calibrated_error) - 2*mz_binwidth, digits = 2)
max_error <- round(max(temp_data$calibrated_error) + 2*mz_binwidth, digits = 2)
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
# aggregate data for plotting
plot_data <- aggregate(cbind(count = calibrated_error) ~ bin + dataset_ID, data = temp_data, FUN = length)
View(plot_data)
plot_data$binstart <- bins[plot_data$bin]
plot_data$binend <- bins[plot_data$bin+1]
head(plot_data)
plot_data$bincenter <- (plot_data$binstart + plot_data$binend) / 2
View(plot_data)
# Create a stacked bar chart
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "Count", title = paste("Histogram of Calibrated Errors for", gsub("^.*/|\\.csv$", "", absolute_file_path))) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
# Adjust axis limits if necessary
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
temp_data$dataset_ID[1]
strsplit(temp_data$dataset_ID, sep = "-")
full_IDs <- strsplit(temp_data$dataset_ID, split = "-")
View(full_IDs)
full_IDs <- unblist(strsplit(temp_data$dataset_ID, split = "-"))
full_IDs <- unlist(strsplit(temp_data$dataset_ID, split = "-"))
full_IDs <- strsplit(temp_data$dataset_ID, split = "-")
full_IDs[[2]]
full_IDs[[]][2]
full_IDs[1:166][2]
temp_data$experiment_tag <- sapply(full_IDs, `[`, 2) # extracts the second element
sapply(full_IDs, `[`, 2)
sapply(full_IDs, `[`, 1)
# clean dataset ID and keep separate from experiment tag
temp_data$dataset_ID <- sapply(full_IDs, `[`, 1) # extracts the first element
# precalculate min and max calibrated error
min_error <- round(min(temp_data$calibrated_error) - 2*mz_binwidth, digits = 2)
max_error <- round(max(temp_data$calibrated_error) + 2*mz_binwidth, digits = 2)
# create bins to plot data by
bins <- seq(min_error, max_error, by = mz_binwidth)
# cut the calibrated errors into bins
temp_data$bin <- cut(temp_data$calibrated_error, bins, include.lowest = TRUE, labels = FALSE)
# aggregate data for plotting
plot_data <- aggregate(cbind(count = calibrated_error) ~ bin + dataset_ID, data = temp_data, FUN = length)
# get bin center for plotting instead of using bin number
plot_data$binstart <- bins[plot_data$bin]
plot_data$binend <- bins[plot_data$bin+1]
plot_data$bincenter <- (plot_data$binstart + plot_data$binend) / 2
head(plot_data)
# Create a stacked bar chart
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "Count", title = paste("Histogram of Calibrated Errors for", gsub("^.*/|\\.csv$", "", absolute_file_path))) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
# Adjust axis limits if necessary
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
View(plot_data)
# create a stacked bar chart type of histogram
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "PSM Count", title = gsub("^.*/|\\.csv$", "", absolute_file_path)) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
# adjust axis limits
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
library(viridis)
# create a stacked bar chart type of histogram
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "PSM Count", title = gsub("^.*/|\\.csv$", "", absolute_file_path)) +
theme_minimal() +
scale_fill_viridis_c()
# adjust axis limits
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
# create a stacked bar chart type of histogram
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "PSM Count", title = gsub("^.*/|\\.csv$", "", absolute_file_path)) +
theme_minimal() +
scale_fill_viridis()
# adjust axis limits
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
# create a stacked bar chart type of histogram
p <- ggplot(plot_data, aes(x = bincenter, y = count, fill = dataset_ID)) +
geom_col(position = "stack", width = mz_binwidth) +  # geom_col is used here for explicit bar widths
scale_x_continuous(name = "Calibrated Error (m/z)", breaks = seq(min(plot_data$binstart), max(plot_data$binend), by = mz_binwidth * 5)) +
labs(y = "PSM Count", title = gsub("^.*/|\\.csv$", "", absolute_file_path)) +
theme_minimal() +
scale_fill_brewer(palette = "Set3") # Use a distinct color palette
# adjust axis limits
p <- p + expand_limits(x = c(min(plot_data$binstart), max(plot_data$binend)))
print(p)
